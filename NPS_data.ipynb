{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Questions\n",
    "\n",
    "- How do we consolidate `Week` and `Location` data from the 2016 filenames to the final 2016 DataFrame?\n",
    "\n",
    "## Steps for Cleaning All Data:\n",
    "---\n",
    "- Step 1: Clean the 2016 Data (Weeks 1-7) into One DataFrame.\n",
    "- Step 2: Clean the 2016 Data (Weeks 8) into One DataFrame.\n",
    "- Step 2.5: Aggregate both 2016 Datasets (Weeks 1-7 and Week 8) into One Bigger DF (Weeks 1-8).\n",
    "- Step 3: Clean the 2017 Data into One DataFrame.\n",
    "- Step 3.5: Aggregate the 2016 DataFrame (Weeks 1-8) and the 2017 DF into One Biggest DF (2016-17). \n",
    "\n",
    "\n",
    "### Observation that 4/5 may not be exactly equivalent to 8/10 as it is to 9/10...\n",
    "\n",
    "- [`STRETCH`] Try both scenarios on any related questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Cleaning?\n",
    "\n",
    "- Some data might be irrelevant, redundant, null, nonsensical\n",
    "- Cleaning involves the steps to reduce the noise in a dataset\n",
    "- CLEANING: Converting a ton of noise, extracting _signal_, and ending up with a **single source of truth**\n",
    "- Signal is data that is valuable towards answering a question; extracting signal is our end goal in all types of data science\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kash Cleaning Tips\n",
    "\n",
    "\n",
    "### Understand what a column (feature) is truly communicating \n",
    "- Examples: [1-5] scale vs. [1-10] vs. \"A little too slow\" text scale, \n",
    "\n",
    "### NULL Values (NaNs)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df16 = [pd.read_csv(f) for f in glob.glob('./SA Feedback Surveys_FINAL/2016/*.csv')]\n",
    "\n",
    "all_csvs = glob.glob(os.path.join('./SA Feedback Surveys_FINAL/2016/', \"*.csv\"))\n",
    "read_all_csvs = (pd.read_csv(f) for f in all_csvs)\n",
    "df = pd.concat(read_all_csvs, ignore_index = True, sort = True)\n",
    "df.head()\n",
    "\n",
    "the_bad_thing = np.nan\n",
    "type(the_bad_thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do List\n",
    "- [ ] Check all columns to see if they have valid responses\n",
    "- [ ] #REF! rows invalid\n",
    "- [ ] Convert all string scors to int values\n",
    "- [ ] Track, location vs popularity\n",
    "- [ ] Understand from which region of the country students are most satisfied or dissatisfied \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 10.,  9.,  3.,  8.,  6.,  7.,  4.,  5.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['How likely is it that you would recommend the Make School Summer Academy to a friend?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27     True\n",
       "28     True\n",
       "29     True\n",
       "       ... \n",
       "962    True\n",
       "963    True\n",
       "964    True\n",
       "965    True\n",
       "966    True\n",
       "967    True\n",
       "968    True\n",
       "969    True\n",
       "970    True\n",
       "971    True\n",
       "972    True\n",
       "973    True\n",
       "974    True\n",
       "975    True\n",
       "976    True\n",
       "977    True\n",
       "978    True\n",
       "979    True\n",
       "980    True\n",
       "981    True\n",
       "982    True\n",
       "983    True\n",
       "984    True\n",
       "985    True\n",
       "986    True\n",
       "987    True\n",
       "988    True\n",
       "989    True\n",
       "990    True\n",
       "991    True\n",
       "Name: How likely is it that you would recommend the Make School Summer Academy to a friend?, Length: 992, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['How likely is it that you would recommend the Make School Summer Academy to a friend?'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 1, 2, 5, nan, '2', '3', '4', '5', '#REF!'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['How well is the schedule paced?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Intro', 'Games', 'Apps', 'VR', 'Average:'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available tracks are Intro, Games, Apps and VR\n",
    "df['What track are you in?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'New York', 'San Francisco', 'Sunnyvale', 'Singapore',\n",
       "       'Los Angeles'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available locations are New York, San Francisco, Sunnyvale, Singapore and Los Angeles\n",
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,  3.,  4.,  5.,  2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['How well are the tutorials paced?'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning/Manipulation on the 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2017 = \"./SA Feedback Surveys_FINAL/2017/Student Feedback Surveys-Superview.csv\"\n",
    "data_2017 = pd.read_csv(path_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to ensure our empty data in our Schedule Pacing column does not contort our findings, we'll replace the NaNs with a \"harmless\" value with a datatype that matches the rest of our column.\n",
    "\n",
    "In this case, since we want to convert our strings to ints, we'll turn our NaNs into ints outside of our expected useful range. \n",
    "\n",
    "Since we want to end up with a range of [1, 5], we'll give our NaN values a value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Just right', 'A little too fast', 'Way too slow',\n",
       "       'A little too slow', 'Way too fast', nan], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2017[\"Schedule Pacing\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clever Data Cleaning for _Scheduling Pacing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_schedule_pacing_2017(data_2017):\n",
    "    \"\"\" Function designed to clean NaNs and convert strings to ints across Scheduling Pacing column of DF 2017. \"\"\"\n",
    "    pacing_map = {\n",
    "        \"Way too slow\": 1,\n",
    "        \"A little too slow\": 2,\n",
    "        \"Just right\": 3,\n",
    "        \"A little too fast\": 4,\n",
    "        \"Way too fast\": 5\n",
    "    }\n",
    "    data_2017[\"Schedule Pacing\"] = data_2017[\"Schedule Pacing\"].replace(pacing_map).fillna(0).astype(int)\n",
    "    return data_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Only call this function when cleaning newly initialized 2017 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017 = clean_schedule_pacing_2017(data_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 1, 2, 5, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2017[\"Schedule Pacing\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_vals = set()\n",
    "\n",
    "# for value in data_2017[\"Rating (Num)\"]:\n",
    "#     unique_vals.update([type(value)])\n",
    "\n",
    "def replace_errors_in_ratings_2017(data_2017):\n",
    "    arg_all_but_errors = (data_2017[\"Rating (Num)\"] != \"#ERROR!\")\n",
    "    data_2017 = data_2017[arg_all_but_errors]\n",
    "    data_2017[\"Rating (Num)\"] = data_2017[\"Rating (Num)\"].astype(int)\n",
    "    return data_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017 = replace_errors_in_ratings_2017(data_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 10,  0,  1,  2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2017[\"Rating (Num)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
